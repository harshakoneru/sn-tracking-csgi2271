{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.00s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Cache filename:  det_best_ckpt.pkl\n",
      "Loaded model from cache\n",
      "True\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "/ext3/miniconda3/envs/ByteTrack/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2023-12-11 13:35:44.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mInitializing tracker for SNMOT-186\u001b[0m\n",
      "\u001b[32m2023-12-11 13:37:25.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 50 frames. Time taken: 101.60. fps: 0.49\u001b[0m\n",
      "\u001b[32m2023-12-11 13:39:07.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 100 frames. Time taken: 203.39. fps: 0.49\u001b[0m\n",
      "\u001b[32m2023-12-11 13:40:43.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 150 frames. Time taken: 299.79. fps: 0.50\u001b[0m\n",
      "\u001b[32m2023-12-11 13:42:39.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 200 frames. Time taken: 415.46. fps: 0.48\u001b[0m\n",
      "\u001b[32m2023-12-11 13:44:04.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 250 frames. Time taken: 500.00. fps: 0.50\u001b[0m\n",
      "\u001b[32m2023-12-11 13:44:56.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 300 frames. Time taken: 552.18. fps: 0.54\u001b[0m\n",
      "\u001b[32m2023-12-11 13:46:16.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 350 frames. Time taken: 632.25. fps: 0.55\u001b[0m\n",
      "\u001b[32m2023-12-11 13:48:00.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 400 frames. Time taken: 736.87. fps: 0.54\u001b[0m\n",
      "\u001b[32m2023-12-11 13:50:26.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 450 frames. Time taken: 882.07. fps: 0.51\u001b[0m\n",
      "\u001b[32m2023-12-11 13:52:04.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 500 frames. Time taken: 980.14. fps: 0.51\u001b[0m\n",
      "\u001b[32m2023-12-11 13:54:01.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 550 frames. Time taken: 1097.19. fps: 0.50\u001b[0m\n",
      "\u001b[32m2023-12-11 13:56:02.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 600 frames. Time taken: 1218.27. fps: 0.49\u001b[0m\n",
      "\u001b[32m2023-12-11 13:57:24.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 650 frames. Time taken: 1300.35. fps: 0.50\u001b[0m\n",
      "\u001b[32m2023-12-11 13:58:08.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 700 frames. Time taken: 1344.07. fps: 0.52\u001b[0m\n",
      "\u001b[32m2023-12-11 13:59:07.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mProcessed 750 frames. Time taken: 1403.17. fps: 0.53\u001b[0m\n",
      "\u001b[32m2023-12-11 13:59:07.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mFinished, results saved to results/allenabled/exp4/SoccerNet-val/mot17epoch14/data\u001b[0m\n",
      "\u001b[32m2023-12-11 13:59:07.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mTime spent: 1322.020, FPS 0.57\u001b[0m\n",
      "\u001b[32m2023-12-11 13:59:07.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mTime spent: 1322.020, FPS 0.57\u001b[0m\n",
      "\u001b[32m2023-12-11 13:59:11.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mLinear interpolation post-processing applied, saved to results/allenabled/exp4/SoccerNet-val/mot17epoch14_post/data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 main2.py --exp_name mot17epoch14\\\n",
    "--post --grid_off --new_kf_off\\\n",
    "--test_dataset --result_folder results/allenabled/exp4 \\\n",
    "--out_path results/allenabled/exp1/trackvis --dataset soccernet \\\n",
    "--w_assoc_emb 0.75 --aw_param 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/scratch/hk3820/ByteTrack/datasets/SoccerNet/annotations/challenge2023last.json\", \"r\") as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ByteTrackV2",
   "language": "python",
   "name": "bytetrackv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
